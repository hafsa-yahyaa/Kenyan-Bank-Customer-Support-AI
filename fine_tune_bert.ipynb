{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ‡°ðŸ‡ª Localized AI: Kenyan Bank Customer Support Classifier\n",
        "**Hafsa Yahya Mohamud**\n",
        "\n",
        "**Mini-Project for Local AI Application**\n",
        "\n",
        "## Objective\n",
        "To fine-tune a Large Language Model (DistilBERT) to understand Kenyan code-mixed text (Swahili, English, Sheng) and categorize customer support queries.\n",
        "\n",
        "## Categories\n",
        "1. **Billing:** Issues with tokens, meters, and KPLC.\n",
        "2. **Reversals:** M-Pesa transactions to wrong numbers.\n",
        "3. **Network:** Data bundles, internet speed, and coverage.\n",
        "4. **General:** Inquiries about location, hours, etc."
      ],
      "metadata": {
        "id": "YuQ9mS5wkoqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the SimpleTransformers library (wraps BERT/DistilBERT)\n",
        "!pip install simpletransformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GREzlCNqhdyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Setup and Data Loading\n",
        "We import necessary libraries and load our custom dataset (`customer_support_data.csv`). We also map our text categories to numbers (0-3) so the model can understand them."
      ],
      "metadata": {
        "id": "m-voYhRFl06W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from sklearn.metrics import accuracy_score\n",
        "import logging\n",
        "\n",
        "# Setup logging to keep output clean\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"customer_support_data.csv\")\n",
        "\n",
        "# Map categories to numbers\n",
        "label_map = {\n",
        "    \"billing_issue\": 0,\n",
        "    \"transaction_reversal\": 1,\n",
        "    \"network_issue\": 2,\n",
        "    \"general_inquiry\": 3\n",
        "}\n",
        "df['labels'] = df['label'].map(label_map)\n",
        "\n",
        "# Split data: 80% for training, 20% for testing\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data Loaded: {len(train_df)} training rows, {len(test_df)} test rows.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-8h8wXETmLZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Configuration\n",
        "We are using **DistilBERT**, a lighter and faster version of the BERT Transformer model. We configure it to train for 5 epochs (loops) using the GPU."
      ],
      "metadata": {
        "id": "stgfvf9bmRx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the model\n",
        "model_args = ClassificationArgs()\n",
        "model_args.num_train_epochs = 5\n",
        "model_args.train_batch_size = 16\n",
        "model_args.overwrite_output_dir = True\n",
        "\n",
        "# Initialize DistilBERT\n",
        "model = ClassificationModel(\n",
        "    \"distilbert\",\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=4,\n",
        "    args=model_args,\n",
        "    use_cuda=True  # Assumes you are using Colab GPU\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FN_uvkFRmb2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training (Fine-Tuning)\n",
        "We now train the model on our specific Kenyan dataset. This is where the \"Local Adaptation\" happens."
      ],
      "metadata": {
        "id": "Oo_J-YYHmj42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.train_model(train_df)\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ej8mUCHrmn7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluation\n",
        "We test the model on the 20% of data it has never seen to calculate the Accuracy score."
      ],
      "metadata": {
        "id": "dKXz6y9amo6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=accuracy_score)\n",
        "\n",
        "print(f\"Model Accuracy: {result['acc'] * 100:.2f}%\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GkrrZge-mvFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Local Adaptation Test (Qualitative)\n",
        "We test the model on new, unseen sentences containing heavy Sheng and local context to prove it works better than a generic model."
      ],
      "metadata": {
        "id": "6x_DdEDamx57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom sentences with local slang\n",
        "test_sentences = [\n",
        "    \"Manze tokens zangu zimeisha na mpesa haifanyi.\",  # Should be Billing\n",
        "    \"Nimetuma pesa wrong number, please reverse.\",      # Should be Reversal\n",
        "    \"Internet iko down sana leo.\",                      # Should be Network\n",
        "    \"Mnafungua saa ngapi?\"                              # Should be General\n",
        "]\n",
        "\n",
        "# Get predictions\n",
        "predictions, raw_outputs = model.predict(test_sentences)\n",
        "\n",
        "# Map numbers back to names\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "print(\"--- Prediction Results ---\")\n",
        "for text, pred_id in zip(test_sentences, predictions):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Prediction: {inv_map[pred_id]}\")\n",
        "    print(\"--------------------------\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KaOq_zBhm0J8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}